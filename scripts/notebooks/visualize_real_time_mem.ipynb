{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the base directory\n",
    "base_dir = '../../results/real/time_memory/{}/run_{}/'\n",
    "\n",
    "graph_info = [\n",
    "    {'graph_name': 'CU', 'n': 49, 'm': 107, 'm/n': 2.18, 'kPathRun': '20250116_210345', 'kLevRun': '20250115_103649'},\n",
    "    {'graph_name': 'AJazz', 'n': 198, 'm': 2742, 'm/n': 13.85, 'kPathRun': '20250116_210346', 'kLevRun': '20250115_103649'},\n",
    "    {'graph_name': 'HM', 'n': 2426, 'm': 16631, 'm/n': 6.85, 'kPathRun': '20250116_210347', 'kLevRun': '20250115_103651'},\n",
    "    {'graph_name': 'ArxAP', 'n': 18771, 'm': 198050, 'm/n': 10.55, 'kPathRun': '20250116_210351', 'kLevRun': '20250115_103704'},\n",
    "    {'graph_name': 'AsCaida', 'n': 26475, 'm': 53381, 'm/n': 2.02, 'kPathRun': '20250116_210635', 'kLevRun': '20250115_103905'},\n",
    "    {'graph_name': 'BrightK', 'n': 58228, 'm': 214078, 'm/n': 3.68, 'kPathRun': '20250116_210957', 'kLevRun': '20250115_103908'},\n",
    "    {'graph_name': 'LMocha', 'n': 104103, 'm': 2193083, 'm/n': 21.07, 'kPathRun': '20250116_211408', 'kLevRun': '20250115_104215'},\n",
    "    {'graph_name': 'FlickrE', 'n': 105938, 'm': 2316948, 'm/n': 21.87, 'kPathRun': '20250116_222732', 'kLevRun': '20250115_110049'},\n",
    "    {'graph_name': 'WordNet', 'n': 146005, 'm': 656999, 'm/n': 4.5, 'kPathRun': '20250116_233806', 'kLevRun': '20250115_112654'},\n",
    "    {'graph_name': 'Douban', 'n': 154908, 'm': 327162, 'm/n': 2.11, 'kPathRun': '20250116_235808', 'kLevRun': '20250115_124239'},\n",
    "    {'graph_name': 'Gowalla', 'n': 196591, 'm': 950327, 'm/n': 4.83, 'kPathRun': '20250117_002520', 'kLevRun': '20250115_124544'},\n",
    "    {'graph_name': 'Dblp', 'n': 317080, 'm': 1049866, 'm/n': 3.31, 'kPathRun': '20250117_011000', 'kLevRun': '20250115_134811'},\n",
    "    {'graph_name': 'Amazon', 'n': 334863, 'm': 925872, 'm/n': 2.76, 'kPathRun': '20250117_121240', 'kLevRun': '20250116_190606'},\n",
    "]\n",
    "\n",
    "# Function to read CSV files\n",
    "def read_data(graph_name, run):\n",
    "    graph_dir = base_dir.format(graph_name, run)\n",
    "    data_list = []\n",
    "\n",
    "    if os.path.isdir(graph_dir):\n",
    "        for heuristic_dir in os.listdir(graph_dir):\n",
    "            if heuristic_dir.startswith('klev_') or heuristic_dir.startswith('kpath_'):\n",
    "                heuristic_path = os.path.join(graph_dir, heuristic_dir)\n",
    "                if os.path.isdir(heuristic_path):\n",
    "                    csv_path = os.path.join(heuristic_path, 'aggregate_results.csv')\n",
    "                    if os.path.exists(csv_path):\n",
    "                        df = pd.read_csv(csv_path)\n",
    "                        if df.empty:\n",
    "                            print(f\"Skipping empty CSV file: {csv_path}\")\n",
    "                            continue\n",
    "                        df['graph_name'] = graph_name\n",
    "                        df['run'] = run\n",
    "                        df['heuristic'] = heuristic_dir\n",
    "                        data_list.append(df)\n",
    "\n",
    "    if not data_list:\n",
    "        print(f\"No valid data found for graph: {graph_name}, run: {run}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "\n",
    "    # Concatenate all the data into a single DataFrame\n",
    "    all_data = pd.concat(data_list, ignore_index=True)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data\n",
    "def plot_data(all_data, graph_name):\n",
    "    if all_data.empty:\n",
    "        print(f\"No data to plot for graph: {graph_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create a figure and axes for the plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize to control the overall size\n",
    "\n",
    "    # Define the order for the heuristics\n",
    "    heuristics_present = all_data['heuristic'].unique()\n",
    "    if any(h.startswith('klev_') for h in heuristics_present):\n",
    "        order = ['klev_0', 'klev_1', 'klev_2', 'klev_N', 'klev_X', 'klev_Y']\n",
    "    else:\n",
    "        order = ['kpath_0', 'kpath_1', 'kpath_2', 'kpath_N', 'kpath_X']\n",
    "\n",
    "    # Plot for Average User Time (s)\n",
    "    sns.lineplot(ax=axes[0], data=all_data, x='K', y='Average User Time (s)', hue='heuristic', hue_order=order, marker='o', ci=None)\n",
    "    axes[0].set_title(f'Average User Time (s) vs K for {graph_name}')\n",
    "    axes[0].set_xticks(range(1, 11))\n",
    "    axes[0].set_xlabel('K')\n",
    "    axes[0].set_ylabel('Average User Time (s)')\n",
    "\n",
    "    # Plot for Average Memory (KB)\n",
    "    sns.lineplot(ax=axes[1], data=all_data, x='K', y='Average Memory (KB)', hue='heuristic', hue_order=order, marker='o', ci=None)\n",
    "    axes[1].set_title(f'Average Memory (KB) vs K for {graph_name}')\n",
    "    axes[1].set_xticks(range(1, 11))\n",
    "    axes[1].set_xlabel('K')\n",
    "    axes[1].set_ylabel('Average Memory (KB)')\n",
    "\n",
    "    # Plot for Passes\n",
    "    sns.lineplot(ax=axes[2], data=all_data, x='K', y='Passes', hue='heuristic', hue_order=order, marker='o', ci=None)\n",
    "    axes[2].set_title(f'Passes vs K for {graph_name}')\n",
    "    axes[2].set_xticks(range(1, 11))\n",
    "    axes[2].set_xlabel('K')\n",
    "    axes[2].set_ylabel('Passes')\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot data for a specific variant\n",
    "def plot_data_for_variant(all_data, graph_name, variant):\n",
    "    if all_data.empty:\n",
    "        print(f\"No data to plot for graph: {graph_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Filter data for the specific variant\n",
    "    variant_data = all_data[all_data['heuristic'] == variant]\n",
    "\n",
    "    if variant_data.empty:\n",
    "        print(f\"No data found for variant: {variant}\")\n",
    "        return\n",
    "\n",
    "    # Create a figure and axes for the plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize to control the overall size\n",
    "\n",
    "    # Plot for Average User Time (s)\n",
    "    sns.lineplot(ax=axes[0], data=variant_data, x='K', y='Average User Time (s)', marker='o', ci=None)\n",
    "    axes[0].set_title(f'Average User Time (s) vs K for {graph_name} ({variant})')\n",
    "    axes[0].set_xticks(range(1, 11))\n",
    "    axes[0].set_xlabel('K')\n",
    "    axes[0].set_ylabel('Average User Time (s)')\n",
    "\n",
    "    # Plot for Average Memory (KB)\n",
    "    sns.lineplot(ax=axes[1], data=variant_data, x='K', y='Average Memory (KB)', marker='o', ci=None)\n",
    "    axes[1].set_title(f'Average Memory (KB) vs K for {graph_name} ({variant})')\n",
    "    axes[1].set_xticks(range(1, 11))\n",
    "    axes[1].set_xlabel('K')\n",
    "    axes[1].set_ylabel('Average Memory (KB)')\n",
    "\n",
    "    # Plot for Passes\n",
    "    sns.lineplot(ax=axes[2], data=variant_data, x='K', y='Passes', marker='o', ci=None)\n",
    "    axes[2].set_title(f'Passes vs K for {graph_name} ({variant})')\n",
    "    axes[2].set_xticks(range(1, 11))\n",
    "    axes[2].set_xlabel('K')\n",
    "    axes[2].set_ylabel('Passes')\n",
    "\n",
    "    # Adjust the layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_for_algorithm(all_data, graph_name, algorithm):\n",
    "    if all_data.empty:\n",
    "        print(f\"No data to plot for graph: {graph_name}\")\n",
    "        return\n",
    "\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Filter data for the specific algorithm\n",
    "    algorithm_data = all_data[all_data['heuristic'].str.startswith(algorithm)]\n",
    "\n",
    "    if algorithm_data.empty:\n",
    "        print(f\"No data found for algorithm: {algorithm}\")\n",
    "        return\n",
    "\n",
    "    # Get unique variants for the algorithm\n",
    "    variants = algorithm_data['heuristic'].unique()\n",
    "    order = ['{}_{}'.format(algorithm, suffix) for suffix in ['0', '1', '2', 'N', 'X', 'Y']]\n",
    "\n",
    "    # Plot data for each variant in the specified order\n",
    "    for variant in order:\n",
    "        if variant in variants:\n",
    "            plot_data_for_variant(all_data, graph_name, variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "\n",
    "# runs for kPath and kLev\n",
    "# graph_runs = [\n",
    "#     {'graph_name': 'AJazz', 'kPathRun': '20250116_210346'},\n",
    "#     {'graph_name': 'Amazon', 'kPathRun': '20250117_121240'},\n",
    "#     {'graph_name': 'ArxAP', 'kPathRun': '20250116_210351'},\n",
    "#     {'graph_name': 'AsCaida', 'kPathRun': '20250116_210635'},\n",
    "#     {'graph_name': 'BrightK', 'kPathRun': '20250116_210957'},\n",
    "#     {'graph_name': 'CU', 'kPathRun': '20250116_210345'},\n",
    "#     {'graph_name': 'Dblp', 'kPathRun': '20250117_011000'},\n",
    "#     {'graph_name': 'Douban', 'kPathRun': '20250116_235808'},\n",
    "#     {'graph_name': 'FlickrE', 'kPathRun': '20250116_222732'},\n",
    "#     {'graph_name': 'Gowalla', 'kPathRun': '20250117_002520'},\n",
    "#     {'graph_name': 'HM', 'kPathRun': '20250116_210347'},\n",
    "#     {'graph_name': 'LMocha', 'kPathRun': '20250116_211408'},\n",
    "#     {'graph_name': 'WordNet', 'kPathRun': '20250116_233806'},\n",
    "# ]\n",
    "\n",
    "# graph_runs = [\n",
    "#     {'graph_name': 'AJazz', 'run': '20250115_103649'},\n",
    "#     {'graph_name': 'Amazon', 'run': '20250116_190606'},\n",
    "#     {'graph_name': 'ArxAP', 'run': '20250115_103704'},\n",
    "#     {'graph_name': 'AsCaida', 'run': '20250115_103905'},\n",
    "#     {'graph_name': 'BrightK', 'run': '20250115_103908'},\n",
    "#     {'graph_name': 'CU', 'run': '20250115_103649'},\n",
    "#     {'graph_name': 'Dblp', 'run': '20250115_134811'},\n",
    "#     {'graph_name': 'Douban', 'run': '20250116_124239'},\n",
    "#     {'graph_name': 'FlickrE', 'run': '20250115_110049'},\n",
    "#     {'graph_name': 'Gowalla', 'run': '20250115_124544'},\n",
    "#     {'graph_name': 'HM', 'run': '20250115_103651'},\n",
    "#     {'graph_name': 'LMocha', 'run': '20250115_104215'},\n",
    "#     {'graph_name': 'WordNet', 'run': '20250115_112654'},\n",
    "# ]\n",
    "\n",
    "# graph_runs = [\n",
    "#     {'graph_name': 'AJazz', 'kPathRun': '20250116_210346', 'kLevRun': '20250115_103649'},\n",
    "#     {'graph_name': 'Amazon', 'kPathRun': '20250117_121240', 'kLevRun': '20250116_190606'},\n",
    "#     {'graph_name': 'ArxAP', 'kPathRun': '20250116_210351', 'kLevRun': '20250115_103704'},\n",
    "#     {'graph_name': 'AsCaida', 'kPathRun': '20250116_210635', 'kLevRun': '20250115_103905'},\n",
    "#     {'graph_name': 'BrightK', 'kPathRun': '20250116_210957', 'kLevRun': '20250115_103908'},\n",
    "#     {'graph_name': 'CU', 'kPathRun': '20250116_210345', 'kLevRun': '20250115_103649'},\n",
    "#     {'graph_name': 'Dblp', 'kPathRun': '20250117_011000', 'kLevRun': '20250115_134811'},\n",
    "#     {'graph_name': 'Douban', 'kPathRun': '20250116_235808', 'kLevRun': '20250116_124239'},\n",
    "#     {'graph_name': 'FlickrE', 'kPathRun': '20250116_222732', 'kLevRun': '20250115_110049'},\n",
    "#     {'graph_name': 'Gowalla', 'kPathRun': '20250117_002520', 'kLevRun': '20250115_124544'},\n",
    "#     {'graph_name': 'HM', 'kPathRun': '20250116_210347', 'kLevRun': '20250115_103651'},\n",
    "#     {'graph_name': 'LMocha', 'kPathRun': '20250116_211408', 'kLevRun': '20250115_104215'},\n",
    "#     {'graph_name': 'WordNet', 'kPathRun': '20250116_233806', 'kLevRun': '20250115_112654'},\n",
    "# ]\n",
    "\n",
    "# graph_name = 'Amazon'\n",
    "# run = '20250117_121240'\n",
    "\n",
    "# graph_name = 'LMocha'\n",
    "# run = '20250116_211408'\n",
    "\n",
    "# Read the data\n",
    "# all_data = read_data(graph_name, run)\n",
    "\n",
    "# Plot the data\n",
    "# plot_data(all_data, graph_name)\n",
    "\n",
    "# Plot the data for a specific heuristic\n",
    "# plot_data_for_variant(all_data, graph_name, 'kpath_N')\n",
    "\n",
    "# Plot the data for all variants of a given algorithm\n",
    "# plot_data_for_algorithm(all_data, graph_name, 'kpath')\n",
    "\n",
    "# for graph in graph_info:\n",
    "#     all_data = read_data(graph['graph_name'], graph['kPathRun'])\n",
    "#     plot_data(all_data, graph['graph_name'])\n",
    "#     all_data = read_data(graph['graph_name'], graph['kLevRun'])\n",
    "#     plot_data(all_data, graph['graph_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the table\n",
    "def generate_table(all_data, algorithm):\n",
    "    # Filter data for the specific algorithm\n",
    "    algorithm_data = all_data[all_data['heuristic'].str.startswith(algorithm)]\n",
    "\n",
    "    if algorithm_data.empty:\n",
    "        print(f\"No data found for algorithm: {algorithm}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "\n",
    "    # Initialize a list to store the rows of the table\n",
    "    table_rows = []\n",
    "\n",
    "    # Get unique graphs\n",
    "    graphs = algorithm_data['graph_name'].unique()\n",
    "\n",
    "    for graph in graphs:\n",
    "        # Retrieve graph info\n",
    "        graph_info_entry = next((item for item in graph_info if item['graph_name'] == graph), None)\n",
    "        if graph_info_entry is None:\n",
    "            continue\n",
    "\n",
    "        n = graph_info_entry['n']\n",
    "        m = graph_info_entry['m']\n",
    "        m_n_ratio = graph_info_entry['m/n']\n",
    "\n",
    "        # Get unique heuristics for the graph\n",
    "        heuristics = algorithm_data[algorithm_data['graph_name'] == graph]['heuristic'].unique()\n",
    "        order = [f'{algorithm}_{suffix}' for suffix in ['0', '1', '2', 'N', 'X', 'Y']]\n",
    "        heuristics = [h for h in order if h in heuristics]\n",
    "\n",
    "        for heuristic in heuristics:\n",
    "            heuristic_data = algorithm_data[(algorithm_data['graph_name'] == graph) & (algorithm_data['heuristic'] == heuristic)]\n",
    "\n",
    "            # Prepare rows for time, memory, and passes\n",
    "            time_row = [graph, n, m, m_n_ratio, heuristic, 'Time (s)']\n",
    "            memory_row = [graph, n, m, m_n_ratio, heuristic, 'Memory (MB)']\n",
    "            passes_row = [graph, n, m, m_n_ratio, heuristic, 'Passes']\n",
    "\n",
    "            for k in range(1, 11):\n",
    "                k_data = heuristic_data[heuristic_data['K'] == k]\n",
    "                if not k_data.empty:\n",
    "                    time_row.append(round(k_data['Average User Time (s)'].values[0], 2))\n",
    "                    memory_row.append(round(k_data['Average Memory (KB)'].values[0] / 1024, 2))\n",
    "                    passes_row.append(round(k_data['Passes'].values[0], 2))\n",
    "                else:\n",
    "                    time_row.append(None)\n",
    "                    memory_row.append(None)\n",
    "                    passes_row.append(None)\n",
    "\n",
    "            # Append the rows to the table\n",
    "            table_rows.append(time_row)\n",
    "            table_rows.append(memory_row)\n",
    "            table_rows.append(passes_row)\n",
    "\n",
    "    # Define the columns of the table\n",
    "    columns = ['Graph', 'N', 'M', 'M/N', 'Heuristic', 'Metric'] + [f'K={k}' for k in range(1, 11)]\n",
    "\n",
    "    # Create a DataFrame from the rows\n",
    "    table_df = pd.DataFrame(table_rows, columns=columns)\n",
    "    return table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the relative table\n",
    "def generate_relative_table(raw_table):\n",
    "    relative_rows = []\n",
    "\n",
    "    # Iterate over the raw table rows\n",
    "    for i in range(0, len(raw_table), 3):\n",
    "        time_row = raw_table.iloc[i].copy()\n",
    "        memory_row = raw_table.iloc[i + 1].copy()\n",
    "        passes_row = raw_table.iloc[i + 2].copy()\n",
    "\n",
    "        # Normalize the time, memory, and passes rows\n",
    "        time_values = time_row[6:].dropna().astype(float)\n",
    "        memory_values = memory_row[6:].dropna().astype(float)\n",
    "        # passes_values = passes_row[6:].dropna().astype(float)\n",
    "\n",
    "        # Replace 0 values with 1 to avoid division by zero\n",
    "        time_values.replace(0, 0.01, inplace=True)\n",
    "        memory_values.replace(0, 0.01, inplace=True)\n",
    "\n",
    "        if not time_values.empty:\n",
    "            min_time = time_values.min()\n",
    "            time_row[6:] = (time_values / min_time).round(2)\n",
    "\n",
    "        if not memory_values.empty:\n",
    "            min_memory = memory_values.min()\n",
    "            memory_row[6:] = (memory_values / min_memory).round(2)\n",
    "\n",
    "        # if not passes_values.empty:\n",
    "        #     min_passes = passes_values.min()\n",
    "        #     passes_row[6:] = (passes_values / min_passes).round(2)\n",
    "\n",
    "        # Append the normalized rows to the relative rows\n",
    "        relative_rows.append(time_row)\n",
    "        relative_rows.append(memory_row)\n",
    "        relative_rows.append(passes_row)\n",
    "\n",
    "    # Create a DataFrame from the relative rows\n",
    "    relative_table = pd.DataFrame(relative_rows, columns=raw_table.columns)\n",
    "    return relative_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Generate table for a real graphs in excel format\n",
    "\n",
    "graph_name = 'Amazon'\n",
    "kPathRun = '20250117_121240'\n",
    "kLevRun = '20250116_190606'\n",
    "\n",
    "# Generate the table for kpath\n",
    "all_data = read_data(graph_name, kPathRun)\n",
    "kpath_table = generate_table(all_data, 'kpath')\n",
    "kpath_relative_table = generate_relative_table(kpath_table)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# filename_raw = f'../../results/real/time_memory/tables/kpath_table_raw_{timestamp}.xlsx'\n",
    "# kpath_table.to_excel(filename_raw, index=False)\n",
    "filename_relative = f'../../results/real/time_memory/tables/kpath_table_relative_{timestamp}.xlsx'\n",
    "kpath_relative_table.to_excel(filename_relative, index=False)\n",
    "\n",
    "all_data = read_data(graph_name, kLevRun)\n",
    "klev_table = generate_table(all_data, 'klev')\n",
    "klev_relative_table = generate_relative_table(klev_table)\n",
    "\n",
    "# filename_raw = f'../../results/real/time_memory/tables/klev_table_raw_{timestamp}.xlsx'\n",
    "# klev_table.to_excel(filename_raw, index=False)\n",
    "filename_relative = f'../../results/real/time_memory/tables/klev_table_relative_{timestamp}.xlsx'\n",
    "klev_relative_table.to_excel(filename_relative, index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate tables for all graphs and save to a single Excel file with four sheets\n",
    "def generate_all_tables(graph_info):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    writer = pd.ExcelWriter(f'../../results/real/time_memory/tables/real_graphs_table_{timestamp}.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    # Initialize DataFrames to store all data\n",
    "    kpath_raw_combined = pd.DataFrame()\n",
    "    kpath_relative_combined = pd.DataFrame()\n",
    "    klev_raw_combined = pd.DataFrame()\n",
    "    klev_relative_combined = pd.DataFrame()\n",
    "\n",
    "    for graph in graph_info:\n",
    "        # Generate the table for kpath\n",
    "        all_data = read_data(graph['graph_name'], graph['kPathRun'])\n",
    "        kpath_table = generate_table(all_data, 'kpath')\n",
    "        kpath_relative_table = generate_relative_table(kpath_table)\n",
    "\n",
    "        # Append to combined DataFrame\n",
    "        kpath_raw_combined = pd.concat([kpath_raw_combined, kpath_table], ignore_index=True)\n",
    "        kpath_relative_combined = pd.concat([kpath_relative_combined, kpath_relative_table], ignore_index=True)\n",
    "\n",
    "        # Generate the table for klev\n",
    "        all_data = read_data(graph['graph_name'], graph['kLevRun'])\n",
    "        klev_table = generate_table(all_data, 'klev')\n",
    "        klev_relative_table = generate_relative_table(klev_table)\n",
    "\n",
    "        # Append to combined DataFrame\n",
    "        klev_raw_combined = pd.concat([klev_raw_combined, klev_table], ignore_index=True)\n",
    "        klev_relative_combined = pd.concat([klev_relative_combined, klev_relative_table], ignore_index=True)\n",
    "\n",
    "    # Write combined DataFrames to Excel file with four sheets\n",
    "    kpath_raw_combined.to_excel(writer, sheet_name='kpath_raw', index=False)\n",
    "    kpath_relative_combined.to_excel(writer, sheet_name='kpath_relative', index=False)\n",
    "    klev_raw_combined.to_excel(writer, sheet_name='klev_raw', index=False)\n",
    "    klev_relative_combined.to_excel(writer, sheet_name='klev_relative', index=False)\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "# Example usage\n",
    "generate_all_tables(graph_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
